================== epoch 1 ==================
1: train_loss=0.6225744583131624
2: train_loss=0.7419363404107676
3: train_loss=0.9292757508454079
4: train_loss=0.6592390589262936
5: train_loss=0.6731967307193805
6: train_loss=0.7711863927049409
7: train_loss=0.6871646031283698
8: train_loss=0.6338267192301048
9: train_loss=0.665757684024681
10: train_loss=0.6509589960054871
11: train_loss=0.6781816819657233
12: train_loss=0.6595460409036895
13: train_loss=0.6470989622538381

evaluation 1: train_loss=0.6938418014947575, test_loss=0.6178168707713677, test_acc=0.4666666666666667

================== epoch 2 ==================
1: train_loss=0.6714402329249404
2: train_loss=0.7144913662194541
3: train_loss=0.4902149835301371
4: train_loss=0.6038110060604539
5: train_loss=0.6241309444098808
6: train_loss=0.6358045070742384
7: train_loss=0.49897802831820315
8: train_loss=0.5622203376179906
9: train_loss=0.46146458020448794
10: train_loss=0.5263744146831802
11: train_loss=0.5014515593736881
12: train_loss=0.460337199398702
13: train_loss=0.5481722712233339

evaluation 2: train_loss=0.5614531870029762, test_loss=0.4397234488701551, test_acc=0.9

================== epoch 3 ==================
1: train_loss=0.7381461039512784
2: train_loss=0.39375802030607676
3: train_loss=0.4620347581006938
4: train_loss=0.35481900762739
5: train_loss=0.44441675445800893
6: train_loss=0.37060841673932665
7: train_loss=0.5266298816324907
8: train_loss=0.5416041508446623
9: train_loss=0.42507369587035587
10: train_loss=0.4999739224768767
11: train_loss=0.5342057235902451
12: train_loss=0.32550869416004813
13: train_loss=0.4258382284130471

evaluation 3: train_loss=0.4648167198592693, test_loss=0.34511918160455196, test_acc=0.9

================== epoch 4 ==================
1: train_loss=0.36732551971100036
2: train_loss=0.5338163871680358
3: train_loss=0.4538763985336111
4: train_loss=0.49972475045919057
5: train_loss=0.5102616587219369
6: train_loss=0.4928441556753407
7: train_loss=0.4012493876624842
8: train_loss=0.3688937035055157
9: train_loss=0.48564598534756964
10: train_loss=0.3864741499619059
11: train_loss=0.4597072802685726
12: train_loss=0.36672637994513496
13: train_loss=0.3291208639081241

evaluation 4: train_loss=0.4350512785283402, test_loss=0.2854946891278267, test_acc=0.9333333333333333

================== epoch 5 ==================
1: train_loss=0.4625970396245866
2: train_loss=0.3903723764981203
3: train_loss=0.442297946446954
4: train_loss=0.4914980877881195
5: train_loss=0.619289448731887
6: train_loss=0.33457902375673354
7: train_loss=0.31282699531074093
8: train_loss=0.2992928942611881
9: train_loss=0.2698046352151645
10: train_loss=0.5781622482676205
11: train_loss=0.29124886072491335
12: train_loss=0.4331380505207147
13: train_loss=0.37437786735785267

evaluation 5: train_loss=0.4076527288080458, test_loss=0.3515440103312828, test_acc=0.9333333333333333

================== epoch 6 ==================
1: train_loss=0.36684450980047373
2: train_loss=0.32771800312733534
3: train_loss=0.43543208976553227
4: train_loss=0.42390732809434256
5: train_loss=0.2454742708893987
6: train_loss=0.44978219423805726
7: train_loss=0.24603419382806133
8: train_loss=0.3085453356773069
9: train_loss=0.3458030994938697
10: train_loss=0.35129228981569244
11: train_loss=0.46683797252728426
12: train_loss=0.4555036068984237
13: train_loss=0.366306801311576

evaluation 6: train_loss=0.36842166888210415, test_loss=0.34789116402070486, test_acc=0.8666666666666667

================== epoch 7 ==================
1: train_loss=0.31477661163185333
2: train_loss=0.6105944902468904
3: train_loss=0.29403561308156323
4: train_loss=0.35292533736744397
5: train_loss=0.7627533659974686
6: train_loss=0.4868516805041671
7: train_loss=0.4827910937162544
8: train_loss=0.5244604194474038
9: train_loss=0.4022281689384045
10: train_loss=0.5193014798859965
11: train_loss=0.431064504691343
12: train_loss=0.5760775156931361
13: train_loss=0.47456391762015926

evaluation 7: train_loss=0.47941724606323716, test_loss=0.44116499303652557, test_acc=0.9666666666666667

================== epoch 8 ==================
1: train_loss=0.44880009691294404
2: train_loss=0.4307405524423613
3: train_loss=0.4415411898209095
4: train_loss=0.4465803248122407
5: train_loss=0.4348671434322699
6: train_loss=0.47120823666279066
7: train_loss=0.4066984730428884
8: train_loss=0.25268335679438986
9: train_loss=0.39015845852438485
10: train_loss=0.3491251303890794
11: train_loss=0.28883837172874227
12: train_loss=0.3450476614883008
13: train_loss=0.3028489436702162

evaluation 8: train_loss=0.38531830305550135, test_loss=0.2360254988882931, test_acc=0.8666666666666667

================== epoch 9 ==================
1: train_loss=0.3184822382557717
2: train_loss=0.303694585954564
3: train_loss=0.47532465715571387
4: train_loss=0.4505375987038586
5: train_loss=0.4136427387784264
6: train_loss=0.49191310120480836
7: train_loss=0.236836156467308
8: train_loss=0.20795716220374963
9: train_loss=0.3250800148075271
10: train_loss=0.4795776472624683
11: train_loss=0.4801315856942607
12: train_loss=0.39863360580667745
13: train_loss=0.3881519048489614

evaluation 9: train_loss=0.38230484593416114, test_loss=0.31385804500674375, test_acc=1.0

================== epoch 10 ==================
1: train_loss=0.3976941002324172
2: train_loss=0.34330696183095233
3: train_loss=0.28777079498636676
4: train_loss=0.35785081705887717
5: train_loss=0.28241785550386045
6: train_loss=0.3068546977944573
7: train_loss=0.36613159294285785
8: train_loss=0.3356023815561437
9: train_loss=0.28963836449894365
10: train_loss=0.4214718376423724
11: train_loss=0.3460211173942728
12: train_loss=0.3049046980623657
13: train_loss=0.3623198422994255

evaluation 10: train_loss=0.33861423552333175, test_loss=0.30884047518236296, test_acc=0.9666666666666667

================== epoch 11 ==================
1: train_loss=0.361053600973722
2: train_loss=0.2513090472337881
3: train_loss=0.26122668713329694
4: train_loss=0.5061083420115274
5: train_loss=0.3344926418565377
6: train_loss=0.34950180427946925
7: train_loss=0.4119353956492022
8: train_loss=0.316160496030871
9: train_loss=0.3079534373086471
10: train_loss=0.23437736817967703
11: train_loss=0.48977102258582333
12: train_loss=0.28844532040015197
13: train_loss=0.31410823405111327

evaluation 11: train_loss=0.3404956459764482, test_loss=0.41749417508942577, test_acc=0.9

================== epoch 12 ==================
1: train_loss=0.32216376853747625
2: train_loss=0.24257835789355944
3: train_loss=0.39069097191802715
4: train_loss=0.3136779434292384
5: train_loss=0.3315890941604561
6: train_loss=0.3529036527625204
7: train_loss=0.3638347930281364
8: train_loss=0.4268151156974379
9: train_loss=0.7117544874468705
10: train_loss=0.5395148227848219
11: train_loss=0.4335087520192057
12: train_loss=0.36987544869846545
13: train_loss=0.8129766371221429

evaluation 12: train_loss=0.43168337273064294, test_loss=0.6803948470703531, test_acc=0.6

================== epoch 13 ==================
1: train_loss=1.0218974471337772
2: train_loss=0.6365239960561945
3: train_loss=0.6724753879555285
4: train_loss=0.6516330907915268
5: train_loss=0.5133931260411487
6: train_loss=0.47706935166262765
7: train_loss=0.5016015812894629
8: train_loss=0.4256272009290429
9: train_loss=0.4274853122268817
10: train_loss=0.5386500575212553
11: train_loss=0.5172430507405724
12: train_loss=0.4223667365635095
13: train_loss=0.40004541314069825

evaluation 13: train_loss=0.5543085963117096, test_loss=0.30810482026232155, test_acc=0.9

================== epoch 14 ==================
1: train_loss=0.3789092589642631
2: train_loss=0.4186042051027575
3: train_loss=0.3037738694339859
4: train_loss=0.344478051911583
5: train_loss=0.3394305253050243
6: train_loss=0.27582193523811893
7: train_loss=0.23901847117532085
8: train_loss=0.3281960397595699
9: train_loss=0.37907100200734967
10: train_loss=0.26027261412385205
11: train_loss=0.270987088799395
12: train_loss=0.27056836986716587
13: train_loss=0.2489568131539638

evaluation 14: train_loss=0.3121606342186422, test_loss=0.30004432835304573, test_acc=0.9666666666666667

================== epoch 15 ==================
1: train_loss=0.3119886081579065
2: train_loss=0.3026813116510435
3: train_loss=0.47752524043398437
4: train_loss=0.24367793758892303
5: train_loss=0.4015240902474081
6: train_loss=0.5144578169119046
7: train_loss=0.48490008273663004
8: train_loss=0.2862584258448431
9: train_loss=0.8688379446536378
10: train_loss=0.30292705763503164
11: train_loss=0.28634869505578003
12: train_loss=0.3741101578660241
13: train_loss=0.40464429879982283

evaluation 15: train_loss=0.4046062821217645, test_loss=0.5561626382780618, test_acc=0.8333333333333334

================== epoch 16 ==================
1: train_loss=0.6906241398479
2: train_loss=0.48367244950004346
3: train_loss=0.36816149513165813
4: train_loss=0.3977651866196147
5: train_loss=0.418651475906846
6: train_loss=0.45064117264848363
7: train_loss=0.447848534206496
8: train_loss=0.45330582261144287
9: train_loss=0.3781442285824738
10: train_loss=0.3800470022310128
11: train_loss=0.3445734175561858
12: train_loss=0.31101131573295326
13: train_loss=0.5139798508753763

evaluation 16: train_loss=0.4337250839577298, test_loss=0.30085565578151724, test_acc=1.0

================== epoch 17 ==================
1: train_loss=0.4980474591475388
2: train_loss=0.3703905195390937
3: train_loss=0.3039634232519069
4: train_loss=0.4674949598149363
5: train_loss=0.31435793835260534
6: train_loss=0.21941263343562056
7: train_loss=0.3594699155485075
8: train_loss=0.2861181032957999
9: train_loss=0.2762728373903983
10: train_loss=0.15518854000859308
11: train_loss=0.3635024375546185
12: train_loss=0.37192034335736934
13: train_loss=0.34199325340391135

evaluation 17: train_loss=0.3329332587769923, test_loss=0.6513435733962919, test_acc=0.9

================== epoch 18 ==================
1: train_loss=0.3710446570541895
2: train_loss=0.22932574617059615
3: train_loss=0.2788515960409085
4: train_loss=0.159976430396873
5: train_loss=0.44623484984890877
6: train_loss=0.1906363987950824
7: train_loss=0.31153199696516676
8: train_loss=0.3100012536820116
9: train_loss=0.36317288590350183
10: train_loss=0.3649495385847835
11: train_loss=0.3300728443659198
12: train_loss=0.3412231775187956
13: train_loss=0.30946365552925376

evaluation 18: train_loss=0.3081911562196916, test_loss=0.21298676904247493, test_acc=0.9333333333333333

================== epoch 19 ==================
1: train_loss=0.4521646523512884
2: train_loss=0.26311296844917487
3: train_loss=0.25838379041743625
4: train_loss=0.3490923519212748
5: train_loss=0.2787562614503601
6: train_loss=0.37834913187204516
7: train_loss=0.30274104079891534
8: train_loss=0.3647279568175516
9: train_loss=0.3520196464217808
10: train_loss=0.31662786154228567
11: train_loss=0.2719900300239248
12: train_loss=0.3482820284170329
13: train_loss=0.35496591510117564

evaluation 19: train_loss=0.3300933565834035, test_loss=0.24867508102899671, test_acc=0.9666666666666667

================== epoch 20 ==================
1: train_loss=0.2289162014144763
2: train_loss=0.2710662194171774
3: train_loss=0.5123537781752792
4: train_loss=0.23223408750912647
5: train_loss=0.34324059666129664
6: train_loss=0.31736709246134304
7: train_loss=0.2961886924605137
8: train_loss=0.1933941878736035
9: train_loss=0.2011580233471816
10: train_loss=0.3773047531869703
11: train_loss=0.45660489940769494
12: train_loss=0.6410393986716263
13: train_loss=0.2256180299837095

evaluation 20: train_loss=0.330498920043846, test_loss=0.3719809531871212, test_acc=0.9333333333333333

================== Final Test Accuracy ==================
test_acc:0.94
Saved Network Parameters!
elapsed time : 4h 48m 30s